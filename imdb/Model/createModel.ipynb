{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.models import model_from_yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filePath):\n",
    "    lemma_result = pd.read_csv(filePath)\n",
    "    return lemma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Clean/lemma_result.csv\"\n",
    "x = readFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beforeCreateModel(max_feat,dataset):\n",
    "    max_fatures = max_feat #จำนวนคำที่ใช้ใน model\n",
    "    tokenizer = Tokenizer(num_words=max_fatures, split=' ') \n",
    "    tokenizer.fit_on_texts(dataset['cleaned_review'].values)\n",
    "    X1 = tokenizer.texts_to_sequences(dataset['cleaned_review'].values)\n",
    "    \n",
    "    feat = pad_sequences(X1, padding='pre') # ลองปรับ padding เป็น Post เผื่อค่าจะดีขึ้น\n",
    "    target = pd.get_dummies(dataset['Label']).values\n",
    "    \n",
    "    return feat,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,    0, ...,  406, 3108,  310],\n",
       "        [   0,    0,    0, ..., 2704,   18,  121],\n",
       "        [   0,    0,    0, ...,   10,    5,  332],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,    4,  645,  771],\n",
       "        [   0,    0,    0, ...,  964,  606,    1],\n",
       "        [   0,    0,    0, ...,   57,  101, 1004]]),\n",
       " array([[0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        ...,\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat,target = beforeCreateModel(max_feat=7000,dataset=x)\n",
    "\n",
    "feat,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(feat,target, test_size = 0.2, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(embed_dim,lstm_out,max_feat,input_length):\n",
    "    embed_dim = embed_dim\n",
    "    lstm_out = lstm_out\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_feat, embed_dim,input_length = input_length))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 150)          1050000   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 580, 150)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,331,001\n",
      "Trainable params: 1,331,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = createModel(embed_dim=150,lstm_out=200,max_feat=7000,input_length=feat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,feat,target,validation_split,epochs,batch_size):\n",
    "    random.seed(10)\n",
    "    history = model.fit(feat, target,validation_split=validation_split, epochs = epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/5\n",
      "640/640 [==============================] - 21s 33ms/sample - loss: 0.6918 - accuracy: 0.5031 - val_loss: 0.6898 - val_accuracy: 0.5188\n",
      "Epoch 2/5\n",
      "640/640 [==============================] - 18s 28ms/sample - loss: 0.6495 - accuracy: 0.7391 - val_loss: 0.6599 - val_accuracy: 0.6562\n",
      "Epoch 3/5\n",
      "640/640 [==============================] - 18s 28ms/sample - loss: 0.4552 - accuracy: 0.9141 - val_loss: 0.6182 - val_accuracy: 0.6625\n",
      "Epoch 4/5\n",
      "640/640 [==============================] - 18s 28ms/sample - loss: 0.1862 - accuracy: 0.9563 - val_loss: 0.6276 - val_accuracy: 0.6687\n",
      "Epoch 5/5\n",
      "640/640 [==============================] - 19s 29ms/sample - loss: 0.0846 - accuracy: 0.9859 - val_loss: 0.7326 - val_accuracy: 0.6938\n"
     ]
    }
   ],
   "source": [
    "trainModel(model,feat=X_train,target=Y_train[:,0],validation_split=0.2,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model,feat,target,batch_size):\n",
    "    score,acc = model.evaluate(feat, target, verbose = 2, batch_size = batch_size)\n",
    "    print(\"score: %.2f\" % (score))\n",
    "    print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 - 1s - loss: 0.6122 - accuracy: 0.7500\n",
      "score: 0.61\n",
      "acc: 0.75\n"
     ]
    }
   ],
   "source": [
    "evaluateModel(model,feat=X_test,target=Y_test[:,0],batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "    # serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(\"addTestTrainSize.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"addTestTrainSize.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
