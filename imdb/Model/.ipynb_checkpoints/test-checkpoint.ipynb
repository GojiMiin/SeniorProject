{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_result = pd.read_csv(\"../Clean/lemma_result.csv\") #Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  Label\n",
      "0  one reviewers mention watch 1 oz episode hook ...      1\n",
      "1  wonderful little production film technique una...      1\n",
      "2  think wonderful way spend time hot summer week...      1\n",
      "3  basically family little boy jake think zombie ...      0\n",
      "4  petter mattei love time money visually stun fi...      1\n"
     ]
    }
   ],
   "source": [
    "print(lemma_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(lemma_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonderful little production film technique unassuming old time bbc fashion give comfort sometimes discomforting sense realism entire piece actors extremely well choose michael sheen get polari voice pat truly see seamless edit guide reference williams diary entries well worth watch terrificly write perform piece masterful production one great master comedy life realism really come home little things fantasy guard rather use traditional dream techniques remain solid disappear play knowledge sense particularly scenes concern orton halliwell set particularly flat halliwell murals decorate every surface terribly well do'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(lemma_result['cleaned_review'])\n",
    "\n",
    "lemma_result['cleaned_review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([X[1, tfidf.vocabulary_['discomforting']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    499\n",
       "1    501\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_result.groupby('Label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = lemma_result.cleaned_review\n",
    "y = lemma_result.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 750 entries with 48.27% negative, 51.73% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_train),\n",
    "                                                                             (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,\n",
    "                                                                            (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 3000 #change size to fit vocab\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(lemma_result['cleaned_review'].values)\n",
    "X1 = tokenizer.texts_to_sequences(lemma_result['cleaned_review'].values)\n",
    "X1 = pad_sequences(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 505) (750, 2)\n",
      "(250, 505) (250, 2)\n"
     ]
    }
   ],
   "source": [
    "Y1 = pd.get_dummies(lemma_result['Label']).values\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1, random_state = 42)\n",
    "print(X1_train.shape,Y1_train.shape)\n",
    "print(X1_test.shape,Y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 505, 150)          450000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 505, 150)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 731,001\n",
      "Trainable params: 731,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 150\n",
    "lstm_out = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 150 samples\n",
      "Epoch 1/20\n",
      "600/600 - 22s - loss: 0.6914 - accuracy: 0.5150 - val_loss: 0.6854 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "600/600 - 17s - loss: 0.6096 - accuracy: 0.7850 - val_loss: 0.5426 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "600/600 - 16s - loss: 0.3541 - accuracy: 0.9017 - val_loss: 0.5739 - val_accuracy: 0.7200\n",
      "Epoch 4/20\n",
      "600/600 - 17s - loss: 0.1343 - accuracy: 0.9617 - val_loss: 0.6418 - val_accuracy: 0.7067\n",
      "Epoch 5/20\n",
      "600/600 - 17s - loss: 0.0636 - accuracy: 0.9900 - val_loss: 0.6693 - val_accuracy: 0.7067\n",
      "Epoch 6/20\n",
      "600/600 - 18s - loss: 0.0403 - accuracy: 0.9933 - val_loss: 0.8503 - val_accuracy: 0.7133\n",
      "Epoch 7/20\n",
      "600/600 - 17s - loss: 0.0153 - accuracy: 0.9983 - val_loss: 0.9222 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "600/600 - 17s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7766 - val_accuracy: 0.7200\n",
      "Epoch 9/20\n",
      "600/600 - 16s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0642 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "600/600 - 17s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.7133\n",
      "Epoch 11/20\n",
      "600/600 - 17s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1687 - val_accuracy: 0.7267\n",
      "Epoch 12/20\n",
      "600/600 - 16s - loss: 0.0116 - accuracy: 0.9950 - val_loss: 1.1348 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "600/600 - 16s - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.8972 - val_accuracy: 0.7200\n",
      "Epoch 14/20\n",
      "600/600 - 17s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0462 - val_accuracy: 0.7267\n",
      "Epoch 15/20\n",
      "600/600 - 16s - loss: 0.0145 - accuracy: 0.9983 - val_loss: 1.0997 - val_accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "600/600 - 16s - loss: 0.0116 - accuracy: 0.9983 - val_loss: 0.8978 - val_accuracy: 0.6933\n",
      "Epoch 17/20\n",
      "600/600 - 16s - loss: 0.0261 - accuracy: 0.9950 - val_loss: 0.9987 - val_accuracy: 0.7400\n",
      "Epoch 18/20\n",
      "600/600 - 16s - loss: 0.0083 - accuracy: 0.9983 - val_loss: 1.1629 - val_accuracy: 0.7400\n",
      "Epoch 19/20\n",
      "600/600 - 17s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2855 - val_accuracy: 0.6933\n",
      "Epoch 20/20\n",
      "600/600 - 16s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2343 - val_accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "random.seed(10)\n",
    "history = model.fit(X1_train, Y1_train[:,0],validation_split=0.2, epochs = 20, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 - 1s - loss: 1.1563 - accuracy: 0.6920\n",
      "score: 1.16\n",
      "acc: 0.69\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X1_test, Y1_test[:,0], verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.14136744e-01],\n",
       "       [9.94408131e-01],\n",
       "       [9.93678272e-01],\n",
       "       [9.99915481e-01],\n",
       "       [9.55830574e-01],\n",
       "       [9.41501130e-05],\n",
       "       [7.35214055e-01],\n",
       "       [9.99822557e-01],\n",
       "       [9.97875571e-01],\n",
       "       [4.93110240e-01],\n",
       "       [5.98928798e-03],\n",
       "       [4.06102017e-02],\n",
       "       [9.98216093e-01],\n",
       "       [2.41826162e-01],\n",
       "       [9.36780512e-01],\n",
       "       [9.72591102e-01],\n",
       "       [9.18236503e-04],\n",
       "       [9.43460763e-01],\n",
       "       [3.51795405e-01],\n",
       "       [1.06711627e-03],\n",
       "       [1.09411803e-05],\n",
       "       [9.96780753e-01],\n",
       "       [9.99504328e-01],\n",
       "       [4.51053120e-03],\n",
       "       [9.99409080e-01],\n",
       "       [8.78319383e-01],\n",
       "       [6.19332016e-01],\n",
       "       [1.38356161e-04],\n",
       "       [4.91073847e-01],\n",
       "       [7.23733800e-04],\n",
       "       [9.99265492e-01],\n",
       "       [9.99673009e-01],\n",
       "       [9.14934993e-01],\n",
       "       [7.54867911e-01],\n",
       "       [9.99445736e-01],\n",
       "       [5.88424392e-02],\n",
       "       [6.33938968e-01],\n",
       "       [8.44697595e-01],\n",
       "       [9.97650206e-01],\n",
       "       [4.93189960e-04],\n",
       "       [5.47132862e-04],\n",
       "       [1.53474975e-02],\n",
       "       [9.98078585e-01],\n",
       "       [9.95920897e-01],\n",
       "       [1.55513454e-03],\n",
       "       [4.04574821e-04],\n",
       "       [1.06095433e-01],\n",
       "       [3.55310855e-03],\n",
       "       [7.23149240e-01],\n",
       "       [1.96068038e-04],\n",
       "       [5.24177194e-01],\n",
       "       [9.99759018e-01],\n",
       "       [9.96885478e-01],\n",
       "       [9.98479187e-01],\n",
       "       [9.96117592e-01],\n",
       "       [3.34030425e-04],\n",
       "       [9.99860525e-01],\n",
       "       [9.36067384e-03],\n",
       "       [9.96018231e-01],\n",
       "       [9.97590303e-01],\n",
       "       [9.98822629e-01],\n",
       "       [3.34202847e-03],\n",
       "       [9.99030232e-01],\n",
       "       [9.71765339e-01],\n",
       "       [9.84461725e-01],\n",
       "       [1.59645423e-01],\n",
       "       [3.07678938e-01],\n",
       "       [3.94841935e-03],\n",
       "       [9.96919632e-01],\n",
       "       [9.88323271e-01],\n",
       "       [9.99898553e-01],\n",
       "       [2.81770481e-03],\n",
       "       [3.11008990e-02],\n",
       "       [9.98966336e-01],\n",
       "       [5.85640192e-01],\n",
       "       [9.34734762e-01],\n",
       "       [9.98942912e-01],\n",
       "       [9.98452902e-01],\n",
       "       [9.99332607e-01],\n",
       "       [2.58524150e-01],\n",
       "       [7.59459615e-01],\n",
       "       [3.40524944e-03],\n",
       "       [9.36531246e-01],\n",
       "       [8.09706211e-01],\n",
       "       [6.66890082e-06],\n",
       "       [2.81313527e-02],\n",
       "       [9.99914289e-01],\n",
       "       [1.65827200e-01],\n",
       "       [7.37488329e-01],\n",
       "       [9.99582469e-01],\n",
       "       [7.25155115e-01],\n",
       "       [3.54861207e-02],\n",
       "       [9.86325324e-01],\n",
       "       [5.64182661e-02],\n",
       "       [3.88488531e-01],\n",
       "       [2.22398899e-03],\n",
       "       [9.97465014e-01],\n",
       "       [9.93703902e-01],\n",
       "       [9.99331892e-01],\n",
       "       [9.02075693e-03],\n",
       "       [9.87302065e-01],\n",
       "       [1.28952277e-04],\n",
       "       [9.99201000e-01],\n",
       "       [8.86179149e-01],\n",
       "       [9.98618960e-01],\n",
       "       [9.98328507e-01],\n",
       "       [7.25121200e-02],\n",
       "       [9.99577343e-01],\n",
       "       [9.99841809e-01],\n",
       "       [1.52707353e-01],\n",
       "       [3.12435860e-03],\n",
       "       [1.97846806e-04],\n",
       "       [6.95547998e-01],\n",
       "       [1.85656045e-02],\n",
       "       [4.02644798e-02],\n",
       "       [1.00379735e-02],\n",
       "       [1.66469663e-01],\n",
       "       [1.58347713e-04],\n",
       "       [9.99315977e-01],\n",
       "       [3.60645920e-01],\n",
       "       [3.08143237e-04],\n",
       "       [8.18286184e-03],\n",
       "       [3.90246749e-01],\n",
       "       [5.23022413e-01],\n",
       "       [9.99678016e-01],\n",
       "       [9.26860869e-01],\n",
       "       [9.78556037e-01],\n",
       "       [9.98851418e-01],\n",
       "       [1.17004476e-01],\n",
       "       [5.07835865e-01],\n",
       "       [9.94457126e-01],\n",
       "       [9.05861816e-05],\n",
       "       [6.92484617e-01],\n",
       "       [6.14432275e-01],\n",
       "       [8.32341552e-01],\n",
       "       [1.19318552e-01],\n",
       "       [5.99302575e-02],\n",
       "       [4.01309917e-05],\n",
       "       [1.61543593e-03],\n",
       "       [8.80164564e-01],\n",
       "       [3.29825853e-04],\n",
       "       [9.79129970e-01],\n",
       "       [9.98321950e-01],\n",
       "       [9.88781631e-01],\n",
       "       [9.88681555e-01],\n",
       "       [9.87277746e-01],\n",
       "       [5.74498713e-01],\n",
       "       [3.44171107e-01],\n",
       "       [2.06022640e-03],\n",
       "       [5.01050527e-05],\n",
       "       [3.16105812e-04],\n",
       "       [9.87501621e-01],\n",
       "       [4.90278155e-01],\n",
       "       [2.90606194e-03],\n",
       "       [9.88967478e-01],\n",
       "       [9.87558246e-01],\n",
       "       [3.08994483e-02],\n",
       "       [1.21781930e-01],\n",
       "       [9.87152874e-01],\n",
       "       [3.94760747e-04],\n",
       "       [4.31391358e-01],\n",
       "       [1.30087743e-03],\n",
       "       [8.88156891e-01],\n",
       "       [1.94592765e-04],\n",
       "       [9.93743002e-01],\n",
       "       [9.87307191e-01],\n",
       "       [9.06813681e-01],\n",
       "       [1.17304847e-02],\n",
       "       [9.81584787e-01],\n",
       "       [2.20728125e-05],\n",
       "       [9.99908566e-01],\n",
       "       [2.48915538e-01],\n",
       "       [9.93342340e-01],\n",
       "       [9.99920487e-01],\n",
       "       [9.54124272e-01],\n",
       "       [5.48378855e-04],\n",
       "       [6.14448898e-02],\n",
       "       [9.81583416e-01],\n",
       "       [9.74662364e-01],\n",
       "       [1.26246642e-03],\n",
       "       [1.58549403e-04],\n",
       "       [9.59841669e-01],\n",
       "       [6.26709824e-03],\n",
       "       [9.97349977e-01],\n",
       "       [5.02918987e-03],\n",
       "       [9.94910300e-01],\n",
       "       [9.49592471e-01],\n",
       "       [5.87367220e-04],\n",
       "       [3.75511944e-02],\n",
       "       [2.02903282e-02],\n",
       "       [1.45311385e-01],\n",
       "       [8.63885581e-02],\n",
       "       [9.79502965e-03],\n",
       "       [9.91544724e-01],\n",
       "       [1.27294715e-02],\n",
       "       [9.99355733e-01],\n",
       "       [1.77069509e-04],\n",
       "       [1.78933993e-01],\n",
       "       [9.99902844e-01],\n",
       "       [9.96584296e-01],\n",
       "       [1.19429771e-02],\n",
       "       [7.38427520e-01],\n",
       "       [9.99522328e-01],\n",
       "       [8.97630870e-01],\n",
       "       [8.36382359e-02],\n",
       "       [9.66082931e-01],\n",
       "       [9.69552755e-01],\n",
       "       [9.99099851e-01],\n",
       "       [9.99366701e-01],\n",
       "       [9.99898434e-01],\n",
       "       [1.25123269e-03],\n",
       "       [7.19913006e-01],\n",
       "       [3.70429363e-03],\n",
       "       [9.99788582e-01],\n",
       "       [9.28110600e-01],\n",
       "       [1.40562244e-02],\n",
       "       [4.80105013e-01],\n",
       "       [9.79540884e-01],\n",
       "       [8.95530820e-01],\n",
       "       [9.99564111e-01],\n",
       "       [4.11088020e-01],\n",
       "       [1.05722593e-02],\n",
       "       [9.98494506e-01],\n",
       "       [2.51331389e-01],\n",
       "       [5.54989159e-01],\n",
       "       [1.28559157e-04],\n",
       "       [1.60822701e-02],\n",
       "       [9.86311138e-01],\n",
       "       [9.96946633e-01],\n",
       "       [9.99422193e-01],\n",
       "       [2.80306535e-03],\n",
       "       [9.85230803e-01],\n",
       "       [2.71964818e-02],\n",
       "       [9.19165313e-01],\n",
       "       [6.36421246e-05],\n",
       "       [4.73003462e-03],\n",
       "       [2.06063763e-04],\n",
       "       [6.48286426e-04],\n",
       "       [9.88041162e-01],\n",
       "       [5.34424325e-05],\n",
       "       [9.97088730e-01],\n",
       "       [9.96671915e-01],\n",
       "       [9.99600351e-01],\n",
       "       [8.94719735e-04],\n",
       "       [8.23560879e-02],\n",
       "       [2.58993834e-01],\n",
       "       [9.84270096e-01],\n",
       "       [9.91037488e-01],\n",
       "       [9.95685101e-01],\n",
       "       [9.76419449e-01]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output= model.predict(X1_test)\n",
    "\n",
    "lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993    tim robbins john cusack two actors appreciate ...\n",
      "859    stereotype plot young fighter try enter compet...\n",
      "298    go see seven pound clearly sure think preview ...\n",
      "553    movie pretty much suck army soldier depict mov...\n",
      "672    see carlo lizzani documentary luchino visconti...\n",
      "                             ...                        \n",
      "462    frustrate movie small southern town overflow p...\n",
      "356    watch last night bowl heartfelt story line exc...\n",
      "2      think wonderful way spend time hot summer week...\n",
      "478    really really really enjoy movies feature ants...\n",
      "695    okay stupid say make another nightmare film la...\n",
      "Name: cleaned_review, Length: 250, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[78, 43],\n",
       "       [34, 95]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "confusion = tf.math.confusion_matrix(labels=Y1_test[:,0], predictions=lstm_output>0.5)\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      0                                     1\n",
      "0  tf.Tensor(78, shape=(), dtype=int32)  tf.Tensor(43, shape=(), dtype=int32)\n",
      "1  tf.Tensor(34, shape=(), dtype=int32)  tf.Tensor(95, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "pf = pd.DataFrame(confusion)\n",
    "\n",
    "print(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEQCAYAAAAEbDfMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfPUlEQVR4nO3de7xVdZ3/8ddb8AKIF0QIK6TULLU0IUdzMs0sNVMrr2Fho6k1WWbmz5oeZdr0oNGmnKxRtCYmzWs2mpbA0A9Tf3kBRUVAqbyQEAiKiqIC5/P74/s9sj2ds8/eh7XOvvB+Ph7rcdb1u75r77M/+7u+l7UVEZiZWbE2anQGzMzakYOrmVkJHFzNzErg4GpmVgIHVzOzEji4mpmVwMG1BUgaJOk3kp6TdN16pDNe0tQi89Yokt4n6ZES0q37tZY0Q9LJReelyzlOlHRHien/TtKEiuXvSFom6W+SRktaKWlAWedvRwMbnYF2IumTwJnA24EXgNnAv0bE+n4ojgJGAttExJq+JhIRVwJXrmdeSicpgJ0i4k897RMRtwM7l3D6qq+1pHOBHSPihBLO3TARcUjnvKQ3A18Bto+IpXn15g3JWAtzybUgks4Efgh8l/ThHA38BDiigOS3Bx5dn8DaTiSVWSjwa51eg+UVgbXPSn6vmltEeFrPCdgSWAkcXWWfTUnBd1GefghsmrftD/yVVFpYCiwGPpO3fRt4FVidz3EScC5wRUXaY4AABublE4G/kErPjwHjK9bfUXHce4F7gefy3/dWbJsBnA/cmdOZCgzv4do68392Rf6PBA4FHgWeAb5esf9ewB+BFXnfi4FN8rY/5Gt5MV/vsRXp/x/gb8AvOtflY3bI59gzL28HLAP27yG/78jXtwJ4GDi8p9e6y3EHd9n+QC2vFbA38P/y+R7oKV953zcDNwBPA8uBi3t47y4CFgLPA7OA93V5fWfmbUuAf8/rNwOuyOmuyO/5yIprOBn4ILAK6MjX+HP+/v9rS+Cn+b17CvgOMKAin3cCP8jvyXca/flsWFxodAbaYcofujWd/3w97HMecBcwAtg2f9jOz9v2z8efB2xMCkovAVvn7efy+mDadfm1f35gSP5Q7Zy3jQJ2zfOvfUCBYcCzwKfyccfn5W3y9hnAn4G3AYPy8sQerq0z/9/M+f9sDg6/BIYCuwIvA2/N+48lBZyBOe/zgDMq0gvSrXfX9L9H+pIaREVwzft8NqczGJgCXNhDXjcG/gR8HdgE+AApIO7c3WvbzfF/t73aawW8kRTMDiXdKR6Ul7ftJu0BpOD7g/w+bgb8Y9f3Li+fAGyTX8OvkL50Nsvb/gh8Ks9vDuyd508FfpNfowH5fdii4hpOrni9K1/bMbw+uP4PcGnO4wjgHuDUinyuAU7PeRvU6M9noyZXCxRjG2BZVL+VHA+cFxFLI+JpUinpUxXbV+ftqyPit6RSQ1/rFDuA3SQNiojFEfFwN/t8BFgQEb+IiDURcRUwH/hoxT7/FRGPRsQq4FpgjyrnXE2qX14NXA0MBy6KiBfy+R8G3gUQEbMi4q583sdJH9T313BN34qIV3J+XiciLgMWAHeTvlD+pYd09iYFnIkR8WpE/B64mfTlsj56eq1OAH4bEb+NiI6ImEYqVR7aTRp7kUrdX42IFyPi5eihvj4iroiI5fk1/D7pS6fz/2U1sKOk4RGxMiLuqli/DemLa21+H56v5yIljQQOIX0Zvhip6uAHwHEVuy2KiB/lvP3de7WhcHAtxnJgeC/1S9sBT1QsP5HXvZZGl+D8En1oRIiIF0m30qcBiyXdIuntNeSnM09vrFj+Wx35WR4Ra/N85wdqScX2VZ3HS3qbpJtzS/TzpHrq4VXSBng6Il7uZZ/LgN2AH0XEKz3ssx2wMCI6KtZ1ve6+6Om12h44WtKKzgn4R9IXQFdvBp7o5UsaAElfkTQv92pYQbpV73wNTyKVoudLulfSYXn9L0il+qslLZL0b5I2rvM6tyeV/hdXXM+lpBJsp4V1ptmWHFyL8UfSbe+RVfZZRPrH7DQ6r+uLF0m3dp3eULkxIqZExEGkD/B8UtDpLT+deXqqj3mqx3+S8rVTRGxBukVXL8dUfXybpM1J9dg/Bc6VNKyHXRcBb5ZU+b9fz3XX+xi5hcAvImKrimlIREzsYd/RvTUCSXofqf75GFLV0VakenMBRMSCiDieFPC+B1wvaUi+K/p2ROxCqm8/DPh0H67nFVKdcuf1bBERu1bs40ft4eBaiIh4jlTf+GNJR0oaLGljSYdI+re821XANyRtK2l43v+KPp5yNrBf7n+4JfC1zg2SRko6XNIQ0odgJbC2mzR+C7xN0iclDZR0LLAL6Ra5bENJ9cIrc6n6c122LwHeWmeaFwGzIuJk4Bbgkh72u5v05XR2fo/2J1WFXF3jeZYAY7oE52quAD4q6cOSBkjaTNL+kt7Uzb73kBqJJkoakvfdt5v9hpLqNZ8GBkr6JrBF50ZJJ0jaNpfOV+TVayUdIOmdub/q86Rqgu7+N3oUEYtJDXbfl7SFpI0k7SCpt2qdDY6Da0Ei4t9JfVy/QfqnXwh8gVT5D6lFdSbwIPAQcF9e15dzTQOuyWnN4vUBcSNSA8ciUmvt+4HPd5PGclLJ5Sukao2zgcMiYllf8lSns4BPkhqSLiNdS6Vzgcn5tvOY3hKTdASpUfG0vOpMYE9J47vuGxGvAoeT6g2XkbrLfToi5teY986BBcsl3dfbzhGxkNQd7+us+7/4Kt189nK1ykeBHYEnST0kju0m2SnA70g9MZ4g3TVV3oofDDwsaSXpS+e4XKXyBuB6UmCdB9xG377gP01qDJxLagS9nu6rOTZoinAJfkMnaSvgkxHxk7y8HfAfEXFUY3NmAJJOA16KiP+WdCIwNSIW5W2Xk7pazW1kHu3vObgaksYAN0fEbg3OivVC0gzgrIiY2ei8WHWuFmgBksbkluHLJD0saWoeA7+DpFslzZJ0e2evgLz+rtxSfF6+PUTS5pKmS7pP0kP5dhpgIrCDpNmSLsjnm5OPuVvSrhV5mSFpbK4T/Fk+x/0VaVmF/FrOlzRZ0oOSrs918gfm1+2h/DpumvefKGlu3vfCvO5cSWdJOgoYB1yZ36tB+f0YJ+lzFfX7nc8i+FGeP0HSPfmYS+VnBPSPRne09dT7ROrEvQbYIy9fS+o/OZ3U4g7wD8Dv8/zNwPF5/jRgZZ4fyLpO48NJnemV05/T5Xxz8vyXgW/n+VGkoaGQuk+dkOe3ItX/DWn0a9VsE+s64O+bl39GqpdfCLwtr/tv4AzSwI5HWHdHuVX+ey6ptAqps/+4ivRnkALutsCfKtb/jtTl6x2kgQMb5/WddcwNf23afXLJtXU8FhGz8/ws0of2vcB1kmaT+hp2Nirsw7qGl19WpCHgu5IeBP6X1LdzZC/nvRY4Os8fU5Huh4Bz8rlnkEYTja77qjYMCyPizjx/BXAg6f18NK+bDOxHamh6Gbhc0sdJ/WVrEmlgyl8k7S1pG9KAgjvzucYC9+b36kDq74lhfbDhPlSh9VR2il9LCoorIqLaqKmuxpNKOGMjYrWkx0lBsUcR8ZSk5ZLeRWq5PjVvEvCJiCj8sX9tqKaGjYhYI2kvUgA8jtTb5AN1nOca0hfgfODXERGSBEyOiK9VP9SK5pJr63oeeEzS0QBKds/b7gI+kecrhyVuCSzNgfUA1g0ieIHUd7InV5O6am0ZEQ/ldVOA0/OHF0nvXt8LamOjJe2T548n3TWMkbRjXvcp4DalgRBbRhr+fAbdDzeu9l7dQBrIcjzrurdNB46SNAJA0jBJXQePWAkcXFvbeOAkSQ+Qxu53NiqdAZwp6R5SVcFzef2VwDhJM/Ox8+G1Pq93Spoj6YJuznM9KUhfW7HufNIwyAdz49f5hV5Ze5kHTMjVMcNIY/E/Q6rSeYj03IRLSEHz5rzfbaT67q5+DlzS2aBVuSEiniX1Pd0+Iu7J6+aS6nin5nSn4T6p/cJdsdqQpMHAqnxbeBypccut+Q3gbm4bLte5tqexwMX5ln0F8E8Nzo/ZBsclVzOzErjO1cysBA6uZmYlcHDdQEk6pdF5sPr4PWstDq4bLn9QW4/fsxbi4GpmVgL3FujFJlsNisFvqDZ4qTW9umIVm2w1qPcdW1DHwvbsYbh6zUtsPHBw7zu2mJdfWcGra17q7Wd+qvrwAUNi+TO1/ajCrAdfmRIRB6/P+WrRnv+FBRr8hqHsd1mvD8O3JvLyGb391qE1k7vmT1rvNJY/s5Z7ptT23KABoxb0yz+Ig6uZtbwAOujodb/+5OBqZi0vCFZHXb+1WDoHVzNrCy65mpkVLAjWNlnjvIOrmbWFjtqeSd5vHFzNrOUFsNbB1cyseC65mpkVLIDVrnM1MytWEK4WMDMrXMDa5oqtDq5m1vrSCK3m4uBqZm1ArGW9nv1SOAdXM2t5qUGruYKrn+dqZi0v9XNVTVMtJH1J0hxJD0s6I68bJmmapAX579bV0nBwNbO20BGqaeqNpN2AzwJ7AbsDh0naCTgHmB4ROwHT83KPHFzNrOUVXHJ9B3BXRLwUEWuA24CPAUcAk/M+k4EjqyXi4GpmLS8Qa9mopgkYLmlmxdT1t8nmAPtJ2kbSYOBQ4M3AyIhYDJD/jqiWJzdomVlbqOWWP1sWEeN62hgR8yR9D5gGrAQeANbUmx+XXM2s5QXi1RhQ01RTehE/jYg9I2I/4BlgAbBE0iiA/HdptTQcXM2s5aVBBBvVNNVC0oj8dzTwceAq4CZgQt5lAnBjtTRcLWBmbaHgQQS/krQNsBr454h4VtJE4FpJJwFPAkdXS8DB1cxaXoRYG8XdiEfE+7pZtxw4sNY0HFzNrC10ePirmVmxUoNWc4Wz5sqNmVkfdDZoNRMHVzNrC2ub7MEtDq5m1vI6R2g1EwdXM2sLHQX2FiiCg6uZtbz04BYHVzOzQgVidY1DW/uLg6uZtbwICh1EUAQHVzNrA/IgAjOzogUuuZqZlcINWmZmBQtq+32s/uTgamYtL/20dnOFs+bKjZlZn9T+s9n9xcHVzFpe4BFaZmalcMnVzKxgEXLJ1cysaKlBy8NfzcwKVuxvaBXBwdXMWl5q0HKdq5lZ4TxCy8ysYB6hZWZWEv9AoZlZwSJgdYeDq5lZoVK1gIOrmVnhmm2EVnOF+jpI2krS5yuWt5N0fSPzZGaN0dkVq5apFpK+LOlhSXMkXSVpM0nDJE2TtCD/3bpaGi0bXIGtgNeCa0QsioijGpgfM2uYVC1Qy9RrStIbgS8C4yJiN2AAcBxwDjA9InYCpuflHpUWXCWNkTRP0mX5G2CqpEGSdpB0q6RZkm6X9Pa8/w6S7pJ0r6TzJK3M6zeXNF3SfZIeknREPsVEYAdJsyVdkM83Jx9zt6RdK/IyQ9JYSUMk/Syf4/6KtMysxXXk39HqbarRQGCQpIHAYGARcAQwOW+fDBxZLYGyS647AT+OiF2BFcAngEnA6RExFjgL+Ene9yLgooh4D+lCOr0MfCwi9gQOAL4vSaRvjT9HxB4R8dUu570aOAZA0ihgu4iYBfwL8Pt8jgOACyQNKfyqzaxfpd4CA2qagOGSZlZMp7w+rXgKuBB4ElgMPBcRU4GREbE477MYGFEtT2U3aD0WEbPz/CxgDPBe4LoUHwHYNP/dh3XfBL8kXRyAgO9K2g/oAN4IjOzlvNcC04BvkYLsdXn9h4DDJZ2VlzcDRgPzKg/OL/YpAINGbl7DZZpZI9U5iGBZRIzraWOuSz0CeAupUHidpBPqzVPZwfWVivm1pKC4IiL2qCON8cC2wNiIWC3pcVJQ7FFEPCVpuaR3AccCp+ZNAj4REY/0cvwkUgmbrd4+IurIq5k1SIE/rf1BUsHwaQBJN5AKhUskjYqIxfmOeGm1RPq7Qet54DFJRwMo2T1vu4tUbQCp8rjTlsDSHFgPALbP618AhlY519XA2cCWEfFQXjcFOD1XKyDp3et7QWbWeAX3FngS2FvS4BwrDiTd3d4ETMj7TABurJZII3oLjAdOkvQA8DCp+A1wBnCmpHuAUcBzef2VwDhJM/Ox8wEiYjlwZ+4qcUE357meFKSvrVh3PrAx8GBu/Dq/0Cszs4YpqrdARNxNih/3AQ+R4uQkUiP6QZIWAAfl5R6VVi0QEY8Du1UsX1ix+eBuDnkK2DsiQtJxwMx83DJSfWx35/hkl1WV51tCl+uLiFWsqyIwszYRIdYUOEIrIr5FarOp9AqpFFuTZhqhNRa4OBfDVwD/1OD8mFkL8VOxehARtwO797qjmVkXfli2mVlJHFzNzArmh2WbmZWkwH6uhXBwNbOWFwFr/LBsM7PiuVrAzKxgrnM1MytJOLiamRXPDVpmZgWLcJ2rmVkJxFr3FjAzK57rXM3MCuZnC5iZlSFSvWszcXA1s7bg3gJmZgULN2iZmZXD1QJmZiVwbwEzs4JFOLiamZXCXbHMzErgOlczs4IFosO9BczMitdkBVcHVzNrA27QMjMrSZMVXZurksLMrI8iVNPUG0k7S5pdMT0v6QxJwyRNk7Qg/926WjoOrmbW8gLo6FBNU69pRTwSEXtExB7AWOAl4NfAOcD0iNgJmJ6Xe+TgamatL4BQbVN9DgT+HBFPAEcAk/P6ycCR1Q50nauZtYU6+rkOlzSzYnlSREzqYd/jgKvy/MiIWJzOFYsljah2EgdXM2sPtQfXZRExrredJG0CHA58rS/ZcbWAmbWB2hqz6uyudQhwX0QsyctLJI0CyH+XVjvYwdXM2kPUONXueNZVCQDcBEzI8xOAG6sd7GoBM2t9AVFDT4BaSRoMHAScWrF6InCtpJOAJ4Gjq6Xh4GpmbaK44BoRLwHbdFm3nNR7oCYOrmbWHppshJaDq5m1BwdXM7OCdQ4iaCIOrmbWFvywbDOzMhTYW6AIvfZzVXKCpG/m5dGS9io/a2ZmtVPUNvWXWgYR/ATYh9ShFuAF4Mel5cjMrF61DiDox+BaS7XAP0TEnpLuB4iIZ/OYWzOzJtGnJ16VqpbgulrSAHLMl7Qt0FFqrszM6tVkDVq1VAv8B+lBsSMk/StwB/DdUnNlZlavjhqnftJryTUirpQ0izTsS8CRETGv9JyZmdWqFfu5ShpN+pmD31Sui4gny8yYmVk9+rMnQC1qqXO9hfS9IGAz4C3AI8CuJebLzKw+rRZcI+KdlcuS9uT1j+EyM7Mu6h6hFRH3SXpPGZlpRh2PrGHV+5f0vqM1jSmLpjQ6C1aHvT78TCHptFy1gKQzKxY3AvYEni4tR2Zm9QqabvhrLSXXoRXza0h1sL8qJztmZn3USiXXPHhg84j4aj/lx8ysT1qmWkDSwIhYkxuwzMyaW6sEV+AeUv3qbEk3AdcBL3ZujIgbSs6bmVntWii4dhoGLAc+wLr+rgE4uJpZU+jvxwnWolpwHZF7CsxhXVDt1GSXYWYbvBbqLTAA2Jzuf6/WwdXMmkorlVwXR8R5/ZYTM7P10ULBtbnK2GZmPWmxOtcD+y0XZmbrq1WCa0QUM+DXzKwfqMl+H6WWXyIwM9ugSNpK0vWS5kuaJ2kfScMkTZO0IP/duloaDq5m1h6K/fXXi4BbI+LtwO7APOAcYHpE7ARMz8s9cnA1s9YX6wYS9Db1RtIWwH7ATwEi4tWIWAEcAUzOu00GjqyWjoOrmbWH2kuuwyXNrJhO6ZLSW0mPVf0vSfdLulzSEGBkRCwGyH9HVMtO3Q/LNjNrSrXf8i+LiHFVtg8kPVfl9Ii4W9JF9FIF0B2XXM2s5YnUW6CWqQZ/Bf4aEXfn5etJwXaJpFEA+e/Saok4uJpZ6yuwzjUi/gYslLRzXnUgMBe4CZiQ100AbqyWjqsFzKw9FDuI4HTgSkmbAH8BPkMqjF4r6STgSeDoagk4uJpZeygwuEbEbKC7etmaR646uJpZW2ilZwuYmbUOB1czs4JF8z1bwMHVzNqDS65mZsVznauZWRkcXM3MClbfE6/6hYOrmbU84WoBM7NSOLiamZXBwdXMrAQOrmZmBWuxn9Y2M2sdDq5mZsXz8FczsxK4WsDMrGgeRGBmVhIHVzOzYnmElplZSdTRXNHVwdXMWp/rXM3MyuFqATOzMji4mpkVzyVXM7MyOLiamRXMv/5qZlY893M1MytLFBddJT0OvACsBdZExDhJw4BrgDHA48AxEfFsT2lsVFhuzMwaSFHbVIcDImKPiBiXl88BpkfETsD0vNwjB1cza31Rx9R3RwCT8/xk4MhqO7dccJV0mqRP5/kTJW1Xse1ySbs0Lndm1ijqqG2qUQBTJc2SdEpeNzIiFgPkvyOqJdByda4RcUnF4onAHGBR3nZyI/JkZo1XR+AcLmlmxfKkiJjUZZ99I2KRpBHANEnz681PvwZXSWOAW4G7gXcDjwKfBvYBLsz5uRf4XES8ImkicDiwBpgaEWdJOhdYSapQHgdcKWlVTuN3wFnAe4C3RMTZ+bwnAmMj4nRJJwBfBDbJ+fh8RKwt+9rNrERBPQ1ayyrqUbtPLqKzwLZU0q+BvYAlkkZFxGJJo4Cl1dJoRLXAzqRvincBzwNnAj8Hjo2Id5IC7Odyy9zHgF3zvt+pTCQirgdmAuNzpfOqis3XAx+vWD4WuEbSO/L8vhGxB6klcHzXDEo6RdJMSTNX80ohF21m5SqqQUvSEElDO+eBD5HukG8CJuTdJgA3VkunEcF1YUTcmeevAA4EHouIR/O6ycB+pMD7MnC5pI8DL9V6goh4GviLpL0lbUMK6Hfmc40F7pU0Oy+/tZvjJ0XEuIgYtzGb9ukizayfFdegNRK4Q9IDwD3ALRFxKzAROEjSAuCgvNyjRtS51nR5EbFG0l6kAHgc8AXgA3Wc5xrgGGA+8OuICEkCJkfE1+rMs5k1sSIHEUTEX4Ddu1m/nBSPatKIkutoSfvk+eOB/wXGSNoxr/sUcJukzYEtI+K3wBnAHt2k9QIwtIfz3EDqKnE8KdBC6pt2VK6kRtIwSduv7wWZWYNFoI7apv7SiJLrPGCCpEuBBcCXgLuA6yR1NmhdAgwDbpS0GemL6cvdpPVz4JKKBq3XRMSzkuYCu0TEPXndXEnfIHWx2AhYDfwz8ETxl2lm/crDX+mIiNO6rJtO6j1QaTGphe51IuLcivlfAb+q2Lx/l30P6+b4a1hXkjWzNuFnC5iZFS2ADfk3tCLicWC3/jynmW0gmiu2uuRqZu3B1QJmZiXwT2ubmRXNP61tZla8NIiguaKrg6uZtQf/hpaZWfFccjUzK5rrXM3MytC/zw2ohYOrmbUHVwuYmRUs6vqZl37h4Gpm7cElVzOzEjRXbHVwNbP2oI7mqhdwcDWz1hd4EIGZWdFEeBCBmVkpHFzNzErg4GpmVjDXuZqZlcO9BczMCheuFjAzK1zg4GpmVormqhVgo0ZnwMysCIqoaaopLWmApPsl3ZyXh0maJmlB/rt1b2k4uJpZe4iobarNl4B5FcvnANMjYidgel6uysHVzFpfBKztqG3qhaQ3AR8BLq9YfQQwOc9PBo7sLR3XuZpZe6i9VDpc0syK5UkRMali+YfA2cDQinUjI2JxOk0sljSit5M4uJpZe6g9uC6LiHHdbZB0GLA0ImZJ2n99suPgamatL4BifkNrX+BwSYcCmwFbSLoCWCJpVC61jgKW9paQ61zNrA0EREdtU7VUIr4WEW+KiDHAccDvI+IE4CZgQt5tAnBjbzlyydXMWl9QU2PVepgIXCvpJOBJ4OjeDnBwNbP2UPAIrYiYAczI88uBA+s53sHVzNqDh7+amRXND24xMyteAH7koJlZCVxyNTMrWpTdW6BuDq5m1voCopc+rP3NwdXM2kMxI7QK4+BqZu3Bda5mZgWLcG8BM7NSuORqZla0INaubXQmXsfB1cxaX3GPHCyMg6uZtQd3xTIzK1YA4ZKrmVnBIlxyNTMrQ7M1aCmarPtCs5H0NPBEo/NRguHAskZnwurSru/Z9hGx7fokIOlW0utTi2URcfD6nK8WDq4bKEkze/oFTGtOfs9ai3+g0MysBA6uZmYlcHDdcE1qdAasbn7PWoiD6wYqIhr6QZW0VtJsSXMkXSdp8Hqk9XNJR+X5yyXtUmXf/SW9tw/neFxSrQ0mpWj0e2b1cXC1RlkVEXtExG7Aq8BplRslDehLohFxckTMrbLL/kDdwdWsXg6u1gxuB3bMpcr/K+mXwEOSBki6QNK9kh6UdCqAkoslzZV0CzCiMyFJMySNy/MHS7pP0gOSpksaQwriX86l5vdJ2lbSr/I57pW0bz52G0lTJd0v6VJA/fuSWKvzIAJrKEkDgUOAW/OqvYDdIuIxSacAz0XEeyRtCtwpaSrwbmBn4J3ASGAu8LMu6W4LXAbsl9MaFhHPSLoEWBkRF+b9fgn8ICLukDQamAK8A/gWcEdEnCfpI8Appb4Q1nYcXK1RBkmanedvB35Kul2/JyIey+s/BLyrsz4V2BLYCdgPuCoi1gKLJP2+m/T3Bv7QmVZEPNNDPj4I7CK9VjDdQtLQfI6P52NvkfRsH6/TNlAOrtYoqyJij8oVOcC9WLkKOD0ipnTZ71DSszqqUQ37QKoa2yciVnWTF4+wsT5znas1synA5yRtDCDpbZKGAH8Ajst1sqOAA7o59o/A+yW9JR87LK9/ARhasd9U4AudC5I6A/4fgPF53SHA1oVdlW0QHFytmV1Oqk+9T9Ic4FLS3davgQXAQ8B/Ard1PTAinibVk94g6QHgmrzpN8DHOhu0gC8C43KD2VzW9Vr4NrCfpPtI1RNPlnSN1qb8bAEzsxK45GpmVgIHVzOzEji4mpmVwMHVzKwEDq5mZiVwcDUzK4GDq5lZCf4/lg/lifN2LSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as plt\n",
    "labels = ['negative','positive']\n",
    "cm = confusion_matrix(Y1_test[:,0], lstm_output>0.5)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels(['']+labels)\n",
    "ax.set_yticklabels(['']+labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  280   45  307    1 1426   65    8 1943  677   25  599  202 1273  346\n",
      "  229   71  340   18  532  478    7  372 2703  287    5  533 1656 1045\n",
      " 1427   18  176    9   83  737  229  307    3   31 1274  119   48 1273\n",
      "   17   35  196   45  103  875 1087  148   57 1657  488 1769  489  678\n",
      " 1944   32 1275  202  520   54  876   78  520 1203   85 1770 2704   18\n",
      "  121]\n"
     ]
    }
   ],
   "source": [
    "print(X1[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewers',\n",
       " 'mention',\n",
       " 'watch',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hook',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happen',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'strike',\n",
       " 'oz',\n",
       " 'scenes',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'show',\n",
       " 'hearted',\n",
       " 'show',\n",
       " 'pull',\n",
       " 'punch',\n",
       " 'regard',\n",
       " 'drug',\n",
       " 'sex',\n",
       " 'violence',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word',\n",
       " 'call',\n",
       " 'oz',\n",
       " 'give',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'focus',\n",
       " 'mainly',\n",
       " 'city',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'front',\n",
       " 'face',\n",
       " 'high',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'many',\n",
       " 'death',\n",
       " 'star',\n",
       " 'deal',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'go',\n",
       " 'show',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'picture',\n",
       " 'paint',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romance',\n",
       " 'oz',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'strike',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'watch',\n",
       " 'develop',\n",
       " 'taste',\n",
       " 'oz',\n",
       " 'get',\n",
       " 'high',\n",
       " 'level',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'crook',\n",
       " 'guard',\n",
       " 'sell',\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'turn',\n",
       " 'prison',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watch',\n",
       " 'oz',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'view',\n",
       " 'thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'side']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.texts_to_sequences(lemma_result['cleaned_review'].values[0])\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "#print(test[1])\n",
    "my_texts = list(map(sequence_to_text, test))\n",
    "my_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2170, 223, 9, 252, 2171, 305, 1343, 141, 576, 143, 26, 76, 873, 2171, 54, 357, 78, 141, 181, 10, 1421, 21, 1654, 21, 548, 1422, 633, 286, 295, 357, 306, 57, 181, 179, 2171, 25, 2172, 2700, 577, 634, 1272, 387, 787, 2701, 1423, 635, 207, 256, 1766, 387, 196, 42, 268, 68, 388, 43, 153, 157, 15, 34, 217, 712, 21, 487, 139, 10, 21, 951, 454, 79, 210, 764, 1767, 1424, 454, 636, 454, 531, 2171, 765, 95, 26, 305, 52, 144, 873, 952, 1655, 34, 874, 9, 617, 953, 2171, 7, 256, 448, 1425, 357, 357, 2429, 1087, 766, 90, 418, 7, 157, 18, 437, 438, 84, 787, 487, 274, 736, 2702, 787, 275, 9, 2171, 111, 98, 1768, 171, 1144, 7, 406, 310]\n"
     ]
    }
   ],
   "source": [
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_2_input to have shape (505,) but got array with shape (129,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-29f3f96be4d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtestList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtestpad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcxx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    583\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected embedding_2_input to have shape (505,) but got array with shape (129,)"
     ]
    }
   ],
   "source": [
    "testpad = pad_sequences(test)\n",
    "cxx = model.predict(testpad)\n",
    "cxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
